{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8hKtniXGqh6KWntgz8a77",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ReiAkio/AI_Project_Semester2/blob/main/Maua_AI_Projeto_Semestre2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filtro dos dados"
      ],
      "metadata": {
        "id": "oiR5GrzM4Ksv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import das Bibliotecas"
      ],
      "metadata": {
        "id": "z4FListe1_Gt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "YqtFDwIG17EX"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import wave\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "import requests\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carregar arquivos de audio do path especificado e aplicar STFT"
      ],
      "metadata": {
        "id": "hq6aXgBW2-Dw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_audio_file(file_path):\n",
        "    # Carregar o arquivo de áudio\n",
        "    y, sr = librosa.load(file_path, mono=True)\n",
        "    # Calcular o STFT\n",
        "    stft = np.abs(librosa.stft(y))\n",
        "    return stft"
      ],
      "metadata": {
        "id": "gJj0IzTT3KFZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extraindo arquivos de audio com STFT"
      ],
      "metadata": {
        "id": "QnbFoFt63LWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install python_speech_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3k9O0lV-3O1u",
        "outputId": "6a4e203b-b2a8-4e04-beaa-e430626b5875"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python_speech_features\n",
            "  Downloading python_speech_features-0.6.tar.gz (5.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: python_speech_features\n",
            "  Building wheel for python_speech_features (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python_speech_features: filename=python_speech_features-0.6-py3-none-any.whl size=5870 sha256=cb075266c5125e3318be0a2ff4a4bb73fcd3f05634661fe1dd17edf6cda057b1\n",
            "  Stored in directory: /root/.cache/pip/wheels/5a/9e/68/30bad9462b3926c29e315df16b562216d12bdc215f4d240294\n",
            "Successfully built python_speech_features\n",
            "Installing collected packages: python_speech_features\n",
            "Successfully installed python_speech_features-0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para extrair características do STFT (frequência dominante e outras)\n",
        "def extract_features(stft, y, sr):\n",
        "    # Calcular frequências para cada bin da FFT\n",
        "    freqs = librosa.fft_frequencies(sr=22050, n_fft=2048)\n",
        "    # Calcular a média do STFT em cada frequência\n",
        "    mean_stft = np.mean(stft, axis=1)\n",
        "    # Encontrar a frequência dominante\n",
        "    dominant_freq = freqs[np.argmax(mean_stft)]\n",
        "\n",
        "    # Calcular MFCCs\n",
        "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
        "\n",
        "    # Calcular o espectrograma de Mel\n",
        "    mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr)\n",
        "\n",
        "    # Calcular o cromagrama\n",
        "    chromagram = librosa.feature.chroma_stft(S=stft, sr=sr)\n",
        "\n",
        "    # Calcular o contraste espectral\n",
        "    spectral_contrast = librosa.feature.spectral_contrast(S=stft, sr=sr)\n",
        "\n",
        "    # Calcular o Rolloff espectral\n",
        "    spectral_rolloff = librosa.feature.spectral_rolloff(S=stft, sr=sr)\n",
        "\n",
        "    # Calcular o Tom médio\n",
        "    pitch = librosa.pitch_tuning(y)\n",
        "    mean_pitch = np.mean(pitch)\n",
        "\n",
        "    # Calcular o Ponto culminante do Spectrograma\n",
        "    spec_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
        "\n",
        "    # Filtrar o sinal harmônico e percussivo\n",
        "    y_harmonic, y_percussive = librosa.effects.hpss(y)\n",
        "\n",
        "    # Calcular o STFT para o sinal harmônico\n",
        "    stft_harmonic = librosa.stft(y_harmonic)\n",
        "\n",
        "    # Calcular o STFT para o sinal percussivo\n",
        "    stft_percussive = librosa.stft(y_percussive)\n",
        "\n",
        "    # Concatenar todas as características extraídas\n",
        "    features = np.concatenate((np.mean(mfccs, axis=1),\n",
        "                               np.mean(mel_spectrogram, axis=1),\n",
        "                               np.mean(chromagram, axis=1),\n",
        "                               np.mean(spectral_contrast, axis=1),\n",
        "                               [dominant_freq],\n",
        "                               [np.mean(spectral_rolloff)],\n",
        "                               [mean_pitch],\n",
        "                               [np.max(spec_centroid)]))\n",
        "\n",
        "    return features"
      ],
      "metadata": {
        "id": "0WrQfU8b3W6K"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aprendizado Supervisionado"
      ],
      "metadata": {
        "id": "xBqmKpUg4FCX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rotulando por caminho"
      ],
      "metadata": {
        "id": "Felxv6DJ39WH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_label_from_path(file_path):\n",
        "    # Extracts the label 'speaker' from 'speakerX.wav'\n",
        "    base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
        "    # Use regular expression to remove trailing digits\n",
        "    label = re.sub(r'\\d+', '', base_name)\n",
        "    return label"
      ],
      "metadata": {
        "id": "hgJ010zQ4Rq2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Organizando os dados para treinos e testes"
      ],
      "metadata": {
        "id": "VFfW9MJy4Wwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(audio_files):\n",
        "    X = []\n",
        "    y = []\n",
        "    for file_path, label in audio_files:\n",
        "\n",
        "        y_data, sr = librosa.load(file_path)\n",
        "        stft = process_audio_file(file_path)\n",
        "\n",
        "        features = extract_features(stft,y_data, sr)\n",
        "\n",
        "\n",
        "        X.append(features)\n",
        "        y.append(label)\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    print(f\"Shape of X: {X.shape}, Shape of y: {y.shape}\")\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "QDXQqoY64aZz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_from_directory(directory_path):\n",
        "    audio_files = []\n",
        "\n",
        "    for root, dirs, files in os.walk(directory_path):\n",
        "        for file in files:\n",
        "            if file.endswith('.wav') or file.endswith('.mp3'):\n",
        "                file_path = os.path.join(root, file)\n",
        "                label = get_label_from_path(file_path)\n",
        "                audio_files.append((file_path, label))\n",
        "\n",
        "    print(f\"Number of audio files: {len(audio_files)}\")\n",
        "    return prepare_data(audio_files)\n"
      ],
      "metadata": {
        "id": "K7td4uO64hgL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normalização"
      ],
      "metadata": {
        "id": "7KDp9tTx4kVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalization(X_train,X_test):\n",
        "    global scaler\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "I6ztQ-3U4l5Q"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aplicando Logistic Regression"
      ],
      "metadata": {
        "id": "upxm_JIv5IYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def logistic_regression_model(X_train,X_test,y_train,y_test):\n",
        "    global logreg_model\n",
        "\n",
        "    # Logistic Regression\n",
        "    logreg_model = LogisticRegression()\n",
        "    logreg_model.fit(X_train, y_train)\n",
        "    logreg_predictions = logreg_model.predict(X_test)\n",
        "    print('Logistic Regression Accuracy: ', accuracy_score(y_test, logreg_predictions))\n",
        "    print('Classification Report for logistic Regression Model:')\n",
        "    print(classification_report(y_test, logreg_predictions))"
      ],
      "metadata": {
        "id": "lvhbKx675KpX"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aplicando SVM"
      ],
      "metadata": {
        "id": "F7dCZkfO52yg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def svm_model(X_train, X_test, y_train, y_test):\n",
        "    svm_clf = SVC()\n",
        "    svm_clf.fit(X_train, y_train)\n",
        "    svm_predictions = svm_clf.predict(X_test)\n",
        "    print('SVM Accuracy: ', accuracy_score(y_test, svm_predictions))\n",
        "    print('Classification Report for SVM Model:')\n",
        "    print(classification_report(y_test, svm_predictions))"
      ],
      "metadata": {
        "id": "TRxXK5655z5l"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aplicando KNN"
      ],
      "metadata": {
        "id": "1li6XXom5_BG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def knn_model(X_train, X_test, y_train, y_test):\n",
        "    knn_clf = KNeighborsClassifier()\n",
        "    knn_clf.fit(X_train, y_train)\n",
        "    knn_predictions = knn_clf.predict(X_test)\n",
        "    print('KNN Accuracy: ', accuracy_score(y_test, knn_predictions))\n",
        "    print('Classification Report for KNN Model:')\n",
        "    print(classification_report(y_test, knn_predictions))"
      ],
      "metadata": {
        "id": "lunkn8-86Bcy"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aplicando Neural Network"
      ],
      "metadata": {
        "id": "PgYqdWhn6CQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def neural_network_model(X_train, X_test, y_train, y_test):\n",
        "    nn_clf = MLPClassifier()\n",
        "    nn_clf.fit(X_train, y_train)\n",
        "    nn_predictions = nn_clf.predict(X_test)\n",
        "    print('Neural Network Accuracy: ', accuracy_score(y_test, nn_predictions))\n",
        "    print('Classification Report for Neural Network Model:')\n",
        "    print(classification_report(y_test, nn_predictions))"
      ],
      "metadata": {
        "id": "tSoaS2hK6G2L"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}