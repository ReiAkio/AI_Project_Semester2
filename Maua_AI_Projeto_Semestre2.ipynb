{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMAZ+CrCqtXEYIxMSLKn4Zw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ReiAkio/AI_Project_Semester2/blob/main/Maua_AI_Projeto_Semestre2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resumo do projeto"
      ],
      "metadata": {
        "id": "nMk0IcCQLt3M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O projeto apresentado constitui uma síntese da etapa de filtragem, treinamento e testes de áudios para desenvolver modelos de Aprendizado de Máquina no contexto de aprendizado supervisionado, conforme proposto no Trabalho de Conclusão de Curso (TCC) intitulado \"Reconhecimento de Voz por Inteligência Artificial em um Ambiente Virtual\". O objetivo central é identificar, a partir de arquivos de áudio, o locutor específico que está falando. Para tal, os dados passam por um processo de filtragem por meio da Transformada de Fourier, seguido por uma etapa de preparação para garantir a organização apropriada. Posteriormente, é realizada a normalização dos dados, assegurando uma comparação justa entre eles. Em seguida, diversos classificadores são aplicados, como Regressão Logística, Máquinas de Vetores de Suporte (SVM), K-Vizinhos Mais Próximos (KNN) e Redes Neurais. O relatório de classificação apresentado proporciona uma análise comparativa da precisão das previsões nos dados de áudio, para a identificação do locutor."
      ],
      "metadata": {
        "id": "c8Te0Iz0Lv6_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nome dos integrantes"
      ],
      "metadata": {
        "id": "TtKuu_-cvyEn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Cindy Natsuki Yoshita RA: 19.00633-0\n",
        "*   Gabriel Belapetravicius Dias RA: 18.00487-3\n",
        "*   Raphael Gueleri Kalaes RA: 18.02011-9\n",
        "*   Thiago Akio Kanada Tanaka RA: 19.01726-0\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RIcJeHH3v00Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filtro dos dados"
      ],
      "metadata": {
        "id": "oiR5GrzM4Ksv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import das Bibliotecas"
      ],
      "metadata": {
        "id": "z4FListe1_Gt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para que seja possível tanto o filtro de voz, quanto o treinamento dos modelos de classificadores, é necessário importar as bibliotecas necessárias"
      ],
      "metadata": {
        "id": "qDyPQDXulXyM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "YqtFDwIG17EX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import os\n",
        "import librosa.display\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utlização dos dados"
      ],
      "metadata": {
        "id": "HWTmKNjfJK88"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Essas duas linhas de código estão usando comandos de terminal para instalar o Git e clonar um repositório do GitHub diretamente no notebook do Google Colab, assim, permitindo que seja utilizado os dados armazenados nele neste notebook."
      ],
      "metadata": {
        "id": "mXz7sdHVljXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install git\n",
        "!git clone https://github.com/ReiAkio/AI_Project_Semester2.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OdniRFvJO0d",
        "outputId": "95ea6f7c-d6b9-47ec-aaca-5707bd374aef"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git is already the newest version (1:2.34.1-1ubuntu1.10).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 19 not upgraded.\n",
            "fatal: destination path 'AI_Project_Semester2' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carregar arquivos de audio do path especificado e aplicar STFT"
      ],
      "metadata": {
        "id": "hq6aXgBW2-Dw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install python_speech_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMsIAIgmqFnb",
        "outputId": "53ba7076-8ea4-499a-d397-ef92add202ca"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python_speech_features in /usr/local/lib/python3.10/dist-packages (0.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui, carrega-se um arquivo de áudio, converte o sinal de áudio para mono e calcula a Transformada de Fourier de Tempo Curto (STFT) desse sinal. Ela retorna a representação STFT."
      ],
      "metadata": {
        "id": "wXewy1yznSEj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_audio_file(file_path):\n",
        "    # Carregar o arquivo de áudio\n",
        "    y, sr = librosa.load(file_path, mono=True)\n",
        "    # Calcular o STFT\n",
        "    stft = np.abs(librosa.stft(y))\n",
        "    return stft"
      ],
      "metadata": {
        "id": "gJj0IzTT3KFZ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extraindo arquivos de audio com STFT"
      ],
      "metadata": {
        "id": "QnbFoFt63LWE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para manipular melhor as ondas sonoras, extrai-se uma variedade de características de um sinal de áudio representado pela Transformada de Fourier de Tempo Curto (STFT). Essas características incluem informações como os coeficientes cepstrais de frequência Mel (MFCCs), o espectrograma de Mel, o cromagrama, o contraste espectral, o Rolloff espectral e outras informações relevantes sobre o sinal de áudio. Essas características são essenciais para análises posteriores e podem será utilizado para treinar modelos de aprendizado de máquina na tarefaa de processamento de áudio."
      ],
      "metadata": {
        "id": "eE5JcvEZqSZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para extrair características do STFT (frequência dominante e outras)\n",
        "def extract_features(stft, y, sr):\n",
        "    # Calcular frequências para cada bin da FFT\n",
        "    freqs = librosa.fft_frequencies(sr=22050, n_fft=2048)\n",
        "    # Calcular a média do STFT em cada frequência\n",
        "    mean_stft = np.mean(stft, axis=1)\n",
        "    # Encontrar a frequência dominante\n",
        "    dominant_freq = freqs[np.argmax(mean_stft)]\n",
        "\n",
        "    # Calcular MFCCs\n",
        "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
        "\n",
        "    # Calcular o espectrograma de Mel\n",
        "    mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr)\n",
        "\n",
        "    # Calcular o cromagrama\n",
        "    chromagram = librosa.feature.chroma_stft(S=stft, sr=sr)\n",
        "\n",
        "    # Calcular o contraste espectral\n",
        "    spectral_contrast = librosa.feature.spectral_contrast(S=stft, sr=sr)\n",
        "\n",
        "    # Calcular o Rolloff espectral\n",
        "    spectral_rolloff = librosa.feature.spectral_rolloff(S=stft, sr=sr)\n",
        "\n",
        "    # Calcular o Tom médio\n",
        "    pitch = librosa.pitch_tuning(y)\n",
        "    mean_pitch = np.mean(pitch)\n",
        "\n",
        "    # Calcular o Ponto culminante do Spectrograma\n",
        "    spec_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
        "\n",
        "    # Bandas de frequência (em Hz) - você pode ajustar esses valores conforme necessário\n",
        "    low_band = (0, 1000)  # Exemplo: 0-1000 Hz\n",
        "    mid_band = (1000, 4000)  # Exemplo: 1000-4000 Hz\n",
        "    high_band = (4000, 20000)  # Exemplo: 4000-20000 Hz\n",
        "\n",
        "    # Calcular a média das amplitudes nas bandas de frequência\n",
        "    low_band_mean = np.mean(np.sum(mel_spectrogram[(dominant_freq >= low_band[0]) & (dominant_freq <= low_band[1])], axis=0))\n",
        "    mid_band_mean = np.mean(np.sum(mel_spectrogram[(dominant_freq >= mid_band[0]) & (dominant_freq <= mid_band[1])], axis=0))\n",
        "    high_band_mean = np.mean(np.sum(mel_spectrogram[(dominant_freq >= high_band[0]) & (dominant_freq <= high_band[1])], axis=0))\n",
        "\n",
        "    # Filtrar o sinal harmônico e percussivo\n",
        "    y_harmonic, y_percussive = librosa.effects.hpss(y)\n",
        "\n",
        "    # Calcular o STFT para o sinal harmônico\n",
        "    stft_harmonic = librosa.stft(y_harmonic)\n",
        "\n",
        "    # Calcular o STFT para o sinal percussivo\n",
        "    stft_percussive = librosa.stft(y_percussive)\n",
        "\n",
        "    # Calcular a energia harmônica\n",
        "    harmonic_energy = np.sum(np.abs(stft_harmonic), axis=0)\n",
        "\n",
        "    # Calcular a relação sinal-ruído harmônico\n",
        "    harmonic_to_noise = np.sum(np.abs(stft_harmonic), axis=0) / np.sum(np.abs(stft_percussive), axis=0)\n",
        "\n",
        "    # Concatenar todas as características extraídas\n",
        "    features = np.concatenate((np.mean(mfccs, axis=1),\n",
        "                               np.mean(mel_spectrogram, axis=1),\n",
        "                               np.mean(chromagram, axis=1),\n",
        "                               np.mean(spectral_contrast, axis=1),\n",
        "                               [dominant_freq],\n",
        "                               [np.mean(spectral_rolloff)],\n",
        "                               [mean_pitch],\n",
        "                               [np.max(spec_centroid)]))\n",
        "\n",
        "    return features"
      ],
      "metadata": {
        "id": "0WrQfU8b3W6K"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aprendizado Supervisionado"
      ],
      "metadata": {
        "id": "xBqmKpUg4FCX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rotulando por caminho"
      ],
      "metadata": {
        "id": "Felxv6DJ39WH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A função get_label_from_path remove o diretório e a extensão do arquivo para obter o nome básico do arquivo e, em seguida, usa expressões regulares para remover quaisquer dígitos numéricos presentes no nome do arquivo."
      ],
      "metadata": {
        "id": "Xu1Z7JZWqzpm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_label_from_path(file_path):\n",
        "    # Extracts the label 'speaker' from 'speakerX.wav'\n",
        "    base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
        "    # Use regular expression to remove trailing digits\n",
        "    label = re.sub(r'\\d+', '', base_name)\n",
        "    return label"
      ],
      "metadata": {
        "id": "hgJ010zQ4Rq2"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Organizando os dados para treinos e testes"
      ],
      "metadata": {
        "id": "VFfW9MJy4Wwz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Após rotular, precisamos processar uma lista de arquivos de áudio e os preparar para treinamento. Para cada arquivo de áudio na lista, carrega os dados de áudio, extrai o STFT e, em seguida, extrai características específicas desse STFT. Os recursos extraídos e os rótulos correspondentes são armazenados em listas separadas. Essas listas são então convertidas em arrays numpy. E então, a função imprime a forma dos arrays para verificação e os retorna."
      ],
      "metadata": {
        "id": "CHk3yHturRa3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(audio_files):\n",
        "    X = []\n",
        "    y = []\n",
        "    for file_path, label in audio_files:\n",
        "\n",
        "        y_data, sr = librosa.load(file_path)\n",
        "        stft = process_audio_file(file_path)\n",
        "\n",
        "        features = extract_features(stft,y_data, sr)\n",
        "\n",
        "\n",
        "        X.append(features)\n",
        "        y.append(label)\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    print(f\"Shape of X: {X.shape}, Shape of y: {y.shape}\")\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "QDXQqoY64aZz"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assim, busca-se todos os arquivos de áudio no diretorio onde estão os arquivos, verificando os formatos de arquivo aceitos (.wav e .mp3). Para cada arquivo encontrado, extrai o rótulo do arquivo utilizando a função get_label_from_path. Em seguida, armazena o caminho do arquivo e o rótulo correspondente em uma lista. Ao final, imprime o número total de arquivos de áudio encontrados e chama a função prepare_data para processar esses arquivos de áudio."
      ],
      "metadata": {
        "id": "8xieBrg4rkp3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_from_directory(directory_path):\n",
        "    audio_files = []\n",
        "\n",
        "    for root, dirs, files in os.walk(directory_path):\n",
        "        for file in files:\n",
        "            if file.endswith('.wav') or file.endswith('.mp3'):\n",
        "                file_path = os.path.join(root, file)\n",
        "                label = get_label_from_path(file_path)\n",
        "                audio_files.append((file_path, label))\n",
        "\n",
        "    print(f\"Number of audio files: {len(audio_files)}\")\n",
        "    return prepare_data(audio_files)"
      ],
      "metadata": {
        "id": "K7td4uO64hgL"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normalização"
      ],
      "metadata": {
        "id": "7KDp9tTx4kVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Precisa-se padronizar a escala dos dados, tornando-os comparáveis e facilitando o treinamento de modelos de machine learning."
      ],
      "metadata": {
        "id": "fLkD5_SIr7Cm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalization(X_train,X_test):\n",
        "    global scaler\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "I6ztQ-3U4l5Q"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparando os dados"
      ],
      "metadata": {
        "id": "Te6XvVD7kUG1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A cedula abaixo define os diretórios de treinamento e teste para os dados de áudio, chamam a função load_data_from_directory para carregar os dados de áudio desses diretórios e, em seguida, normalizam os conjuntos de dados de treinamento e teste com a função normalization. O processo de normalização é essencial para padronizar a escala dos dados e melhorar a eficácia dos algoritmos de aprendizado de máquina."
      ],
      "metadata": {
        "id": "x3nM8JHItWba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_directory = 'AI_Project_Semester2/data/train_audio/AudiosDeTreino'\n",
        "test_data_directory = 'AI_Project_Semester2/data/test_audio/_audios_teste'\n",
        "X_train, y_train = load_data_from_directory(train_data_directory)\n",
        "X_test, y_test = load_data_from_directory(test_data_directory)\n",
        "normalization(X_train, X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTV6x4B4kWPS",
        "outputId": "6ffc4278-f11f-4307-9ac8-1ebf6d239ff3"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of audio files: 73\n",
            "Shape of X: (73, 164), Shape of y: (73,)\n",
            "Number of audio files: 25\n",
            "Shape of X: (25, 164), Shape of y: (25,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aplicando Logistic Regression"
      ],
      "metadata": {
        "id": "upxm_JIv5IYR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "É feito o treinamento e testes utilizando o modelo Logistic Regression. A Regressão Logística é um modelo estatístico usado para prever a probabilidade de ocorrência de um evento, com base em uma série de variáveis explanatórias. É comumente utilizado para problemas de classificação binária, nos quais o objetivo é prever se uma instância pertence a uma classe específica ou não. Este modelo estima as chances de uma resposta categórica, utilizando a função logística para modelar a relação entre as variáveis independentes e a variável dependente. A regressão logística é frequentemente utilizada para interpretar a influência das variáveis independentes na probabilidade de ocorrência de um evento."
      ],
      "metadata": {
        "id": "I4mOIbo4tvEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logreg_model = LogisticRegression(max_iter=6000)\n",
        "logreg_model.fit(X_train, y_train)\n",
        "logreg_predictions = logreg_model.predict(X_test)\n",
        "print('Logistic Regression Accuracy: ', accuracy_score(y_test, logreg_predictions))\n",
        "print('Classification Report for logistic Regression Model:')\n",
        "print(classification_report(y_test, logreg_predictions))"
      ],
      "metadata": {
        "id": "lvhbKx675KpX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "997bafdc-9956-4dbf-c37e-03001d57e376"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy:  0.72\n",
            "Classification Report for logistic Regression Model:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Acoba       1.00      1.00      1.00         1\n",
            "          Ba       0.50      1.00      0.67         1\n",
            "       Cindy       0.00      0.00      0.00         1\n",
            "     Eduardo       1.00      1.00      1.00         2\n",
            "          Ha       1.00      1.00      1.00         2\n",
            "       Harry       1.00      0.50      0.67         2\n",
            "       Nakai       1.00      1.00      1.00         2\n",
            "   Penterist       0.33      1.00      0.50         2\n",
            "     Raphael       1.00      1.00      1.00         2\n",
            "       Ruivo       1.00      1.00      1.00         2\n",
            "        Teko       0.00      0.00      0.00         2\n",
            "         bia       0.50      1.00      0.67         1\n",
            "    fernanda       0.00      0.00      0.00         1\n",
            "irmamichelli       0.00      0.00      0.00         1\n",
            "    michelli       0.50      1.00      0.67         1\n",
            "      nicole       0.00      0.00      0.00         1\n",
            "      sergio       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           0.72        25\n",
            "   macro avg       0.58      0.68      0.60        25\n",
            "weighted avg       0.65      0.72      0.65        25\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aplicando SVM"
      ],
      "metadata": {
        "id": "F7dCZkfO52yg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "É feito o treinamento e testes utilizando o modelo SVM. SVM (Support Vector Machine) é um algoritmo de aprendizado de máquina supervisionado usado para tarefas de classificação e regressão. Na classificação, o SVM mapeia os dados em um espaço de alta dimensionalidade para encontrar um hiperplano que melhor separa as classes de dados. Este algoritmo procura encontrar a melhor margem possível entre os pontos de dados das diferentes classes, maximizando a distância entre os pontos mais próximos de cada classe e o hiperplano. SVMs também podem lidar com conjuntos de dados não lineares, usando truques de kernel para mapear os dados em um espaço de dimensão superior. Este método é eficaz em conjuntos de dados de pequeno e médio porte e é amplamente utilizado em problemas de classificação, como reconhecimento de padrões e análise de texto."
      ],
      "metadata": {
        "id": "8My_DK9puB5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm_model = SVC()\n",
        "svm_model.fit(X_train, y_train)\n",
        "svm_predictions = svm_model.predict(X_test)\n",
        "print('SVM Accuracy: ', accuracy_score(y_test, svm_predictions))\n",
        "print('Classification Report for SVM Model:')\n",
        "print(classification_report(y_test, svm_predictions))\n",
        "\n",
        "print('Confusion Matrix for SVM Model:')\n",
        "print(confusion_matrix(y_test, svm_predictions))"
      ],
      "metadata": {
        "id": "TRxXK5655z5l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "582f299f-6549-49ea-8982-3ca9ed428de0"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy:  0.44\n",
            "Classification Report for SVM Model:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Acoba       0.00      0.00      0.00         1\n",
            "          Ba       0.50      1.00      0.67         1\n",
            "       Cindy       0.00      0.00      0.00         1\n",
            "     Eduardo       0.00      0.00      0.00         2\n",
            "          Ha       0.00      0.00      0.00         2\n",
            "       Harry       0.33      0.50      0.40         2\n",
            "       Nakai       0.00      0.00      0.00         2\n",
            "   Penterist       0.67      1.00      0.80         2\n",
            "     Raphael       0.40      1.00      0.57         2\n",
            "       Ruivo       1.00      1.00      1.00         2\n",
            "        Teko       0.25      0.50      0.33         2\n",
            "         bia       0.00      0.00      0.00         1\n",
            "    fernanda       0.00      0.00      0.00         1\n",
            "irmamichelli       0.00      0.00      0.00         1\n",
            "    michelli       0.50      1.00      0.67         1\n",
            "      nicole       0.00      0.00      0.00         1\n",
            "      sergio       0.33      1.00      0.50         1\n",
            "\n",
            "    accuracy                           0.44        25\n",
            "   macro avg       0.23      0.41      0.29        25\n",
            "weighted avg       0.27      0.44      0.32        25\n",
            "\n",
            "Confusion Matrix for SVM Model:\n",
            "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aplicando KNN"
      ],
      "metadata": {
        "id": "1li6XXom5_BG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "É feito o treinamento e testes utilizando o modelo KNN. KNN (K-Nearest Neighbors) é um algoritmo de aprendizado de máquina supervisionado que pode ser usado para classificação e regressão. O algoritmo funciona encontrando os K pontos de dados mais próximos a uma nova observação e prevendo o rótulo ou valor com base nos rótulos ou valores desses pontos vizinhos. Na classificação, o KNN atribui a classe mais comum entre os vizinhos mais próximos como o rótulo de classificação para o novo ponto de dados, enquanto na regressão, calcula a média dos valores dos vizinhos mais próximos para prever o valor. O valor de K, ou o número de vizinhos considerados, é um hiperparâmetro crítico que influencia o desempenho do modelo. O KNN é simples e fácil de implementar, sendo particularmente útil em conjuntos de dados pequenos e médios."
      ],
      "metadata": {
        "id": "C7SUSFwyuHUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
        "knn_model.fit(X_train, y_train)\n",
        "knn_predictions = knn_model.predict(X_test)\n",
        "print('KNN Accuracy: ', accuracy_score(y_test, knn_predictions))\n",
        "print('Classification Report for KNN Model:')\n",
        "print(classification_report(y_test, knn_predictions))"
      ],
      "metadata": {
        "id": "lunkn8-86Bcy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f2c472b-37c5-4ba7-919a-526bd2d68214"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Accuracy:  0.4\n",
            "Classification Report for KNN Model:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Acoba       0.50      1.00      0.67         1\n",
            "        Akio       0.00      0.00      0.00         0\n",
            "      Alexia       0.00      0.00      0.00         0\n",
            "          Ba       0.33      1.00      0.50         1\n",
            "       Cindy       0.00      0.00      0.00         1\n",
            "     Eduardo       0.50      1.00      0.67         2\n",
            "          Ha       0.00      0.00      0.00         2\n",
            "       Harry       0.33      0.50      0.40         2\n",
            "       Nakai       0.00      0.00      0.00         2\n",
            "   Penterist       1.00      1.00      1.00         2\n",
            "     Raphael       0.00      0.00      0.00         2\n",
            "       Ruivo       1.00      1.00      1.00         2\n",
            "        Teko       0.00      0.00      0.00         2\n",
            "         bia       0.00      0.00      0.00         1\n",
            "    fernanda       0.00      0.00      0.00         1\n",
            "irmamichelli       0.00      0.00      0.00         1\n",
            "    michelli       1.00      1.00      1.00         1\n",
            "      nicole       0.00      0.00      0.00         1\n",
            "      sergio       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.40        25\n",
            "   macro avg       0.25      0.34      0.28        25\n",
            "weighted avg       0.30      0.40      0.33        25\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aplicando Neural Network"
      ],
      "metadata": {
        "id": "PgYqdWhn6CQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nn_clf = MLPClassifier()\n",
        "nn_clf.fit(X_train, y_train)\n",
        "nn_predictions = nn_clf.predict(X_test)\n",
        "print('Neural Network Accuracy: ', accuracy_score(y_test, nn_predictions))\n",
        "print('Classification Report for Neural Network Model:')\n",
        "print(classification_report(y_test, nn_predictions))"
      ],
      "metadata": {
        "id": "tSoaS2hK6G2L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "835d6090-f995-4d43-c03a-45c80385a20d"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural Network Accuracy:  0.48\n",
            "Classification Report for Neural Network Model:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Acoba       1.00      1.00      1.00         1\n",
            "      Alexia       0.00      0.00      0.00         0\n",
            "          Ba       1.00      1.00      1.00         1\n",
            "       Cindy       0.00      0.00      0.00         1\n",
            "     Eduardo       0.00      0.00      0.00         2\n",
            "          Ha       0.00      0.00      0.00         2\n",
            "       Harry       1.00      0.50      0.67         2\n",
            "       Nakai       1.00      1.00      1.00         2\n",
            "   Penterist       0.00      0.00      0.00         2\n",
            "     Raphael       0.67      1.00      0.80         2\n",
            "       Ruivo       1.00      1.00      1.00         2\n",
            "        Teko       0.00      0.00      0.00         2\n",
            "         bia       0.25      1.00      0.40         1\n",
            "     eduardo       0.00      0.00      0.00         0\n",
            "    fernanda       0.00      0.00      0.00         1\n",
            "irmamichelli       0.00      0.00      0.00         1\n",
            "    michelli       1.00      1.00      1.00         1\n",
            "      nicole       0.00      0.00      0.00         1\n",
            "      sergio       0.50      1.00      0.67         1\n",
            "\n",
            "    accuracy                           0.48        25\n",
            "   macro avg       0.39      0.45      0.40        25\n",
            "weighted avg       0.44      0.48      0.44        25\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}