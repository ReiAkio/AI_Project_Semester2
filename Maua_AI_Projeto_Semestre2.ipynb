{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPv7kv1LOVTQ1vr8V11kZ7c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ReiAkio/AI_Project_Semester2/blob/main/Maua_AI_Projeto_Semestre2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filtro dos dados"
      ],
      "metadata": {
        "id": "oiR5GrzM4Ksv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import das Bibliotecas"
      ],
      "metadata": {
        "id": "z4FListe1_Gt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YqtFDwIG17EX"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import wave\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "\n",
        "import requests\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utlização dos dados"
      ],
      "metadata": {
        "id": "HWTmKNjfJK88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install git\n",
        "!git clone https://github.com/ReiAkio/AI_Project_Semester2.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OdniRFvJO0d",
        "outputId": "a448112f-05cf-4160-b7fd-6e1df92d4d4d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git is already the newest version (1:2.34.1-1ubuntu1.10).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 19 not upgraded.\n",
            "Cloning into 'AI_Project_Semester2'...\n",
            "remote: Enumerating objects: 171, done.\u001b[K\n",
            "remote: Counting objects: 100% (171/171), done.\u001b[K\n",
            "remote: Compressing objects: 100% (166/166), done.\u001b[K\n",
            "remote: Total 171 (delta 1), reused 165 (delta 1), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (171/171), 27.78 MiB | 14.66 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n",
            "Updating files: 100% (163/163), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carregar arquivos de audio do path especificado e aplicar STFT"
      ],
      "metadata": {
        "id": "hq6aXgBW2-Dw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_audio_file(file_path):\n",
        "    # Carregar o arquivo de áudio\n",
        "    y, sr = librosa.load(file_path, mono=True)\n",
        "    # Calcular o STFT\n",
        "    stft = np.abs(librosa.stft(y))\n",
        "    return stft"
      ],
      "metadata": {
        "id": "gJj0IzTT3KFZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extraindo arquivos de audio com STFT"
      ],
      "metadata": {
        "id": "QnbFoFt63LWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install python_speech_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3k9O0lV-3O1u",
        "outputId": "b1697260-d8f6-4faf-8b89-2eda2395a1cd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python_speech_features\n",
            "  Downloading python_speech_features-0.6.tar.gz (5.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: python_speech_features\n",
            "  Building wheel for python_speech_features (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python_speech_features: filename=python_speech_features-0.6-py3-none-any.whl size=5870 sha256=0b2aeae0c779ec7881d79595f2758a029fb3628079158aa335e8ff8a074b85a6\n",
            "  Stored in directory: /root/.cache/pip/wheels/5a/9e/68/30bad9462b3926c29e315df16b562216d12bdc215f4d240294\n",
            "Successfully built python_speech_features\n",
            "Installing collected packages: python_speech_features\n",
            "Successfully installed python_speech_features-0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para extrair características do STFT (frequência dominante e outras)\n",
        "def extract_features(stft, y, sr):\n",
        "    # Calcular frequências para cada bin da FFT\n",
        "    freqs = librosa.fft_frequencies(sr=22050, n_fft=2048)\n",
        "    # Calcular a média do STFT em cada frequência\n",
        "    mean_stft = np.mean(stft, axis=1)\n",
        "    # Encontrar a frequência dominante\n",
        "    dominant_freq = freqs[np.argmax(mean_stft)]\n",
        "\n",
        "    # Calcular MFCCs\n",
        "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
        "\n",
        "    # Calcular o espectrograma de Mel\n",
        "    mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr)\n",
        "\n",
        "    # Calcular o cromagrama\n",
        "    chromagram = librosa.feature.chroma_stft(S=stft, sr=sr)\n",
        "\n",
        "    # Calcular o contraste espectral\n",
        "    spectral_contrast = librosa.feature.spectral_contrast(S=stft, sr=sr)\n",
        "\n",
        "    # Calcular o Rolloff espectral\n",
        "    spectral_rolloff = librosa.feature.spectral_rolloff(S=stft, sr=sr)\n",
        "\n",
        "    # Calcular o Tom médio\n",
        "    pitch = librosa.pitch_tuning(y)\n",
        "    mean_pitch = np.mean(pitch)\n",
        "\n",
        "    # Calcular o Ponto culminante do Spectrograma\n",
        "    spec_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
        "\n",
        "    # Filtrar o sinal harmônico e percussivo\n",
        "    y_harmonic, y_percussive = librosa.effects.hpss(y)\n",
        "\n",
        "    # Calcular o STFT para o sinal harmônico\n",
        "    stft_harmonic = librosa.stft(y_harmonic)\n",
        "\n",
        "    # Calcular o STFT para o sinal percussivo\n",
        "    stft_percussive = librosa.stft(y_percussive)\n",
        "\n",
        "    # Concatenar todas as características extraídas\n",
        "    features = np.concatenate((np.mean(mfccs, axis=1),\n",
        "                               np.mean(mel_spectrogram, axis=1),\n",
        "                               np.mean(chromagram, axis=1),\n",
        "                               np.mean(spectral_contrast, axis=1),\n",
        "                               [dominant_freq],\n",
        "                               [np.mean(spectral_rolloff)],\n",
        "                               [mean_pitch],\n",
        "                               [np.max(spec_centroid)]))\n",
        "\n",
        "    return features"
      ],
      "metadata": {
        "id": "0WrQfU8b3W6K"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aprendizado Supervisionado"
      ],
      "metadata": {
        "id": "xBqmKpUg4FCX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rotulando por caminho"
      ],
      "metadata": {
        "id": "Felxv6DJ39WH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_label_from_path(file_path):\n",
        "    # Extracts the label 'speaker' from 'speakerX.wav'\n",
        "    base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
        "    # Use regular expression to remove trailing digits\n",
        "    label = re.sub(r'\\d+', '', base_name)\n",
        "    return label"
      ],
      "metadata": {
        "id": "hgJ010zQ4Rq2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Organizando os dados para treinos e testes"
      ],
      "metadata": {
        "id": "VFfW9MJy4Wwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(audio_files):\n",
        "    X = []\n",
        "    y = []\n",
        "    for file_path, label in audio_files:\n",
        "\n",
        "        y_data, sr = librosa.load(file_path)\n",
        "        stft = process_audio_file(file_path)\n",
        "\n",
        "        features = extract_features(stft,y_data, sr)\n",
        "\n",
        "\n",
        "        X.append(features)\n",
        "        y.append(label)\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    print(f\"Shape of X: {X.shape}, Shape of y: {y.shape}\")\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "QDXQqoY64aZz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_from_directory(directory_path):\n",
        "    audio_files = []\n",
        "\n",
        "    for root, dirs, files in os.walk(directory_path):\n",
        "        for file in files:\n",
        "            if file.endswith('.wav') or file.endswith('.mp3'):\n",
        "                file_path = os.path.join(root, file)\n",
        "                label = get_label_from_path(file_path)\n",
        "                audio_files.append((file_path, label))\n",
        "\n",
        "    print(f\"Number of audio files: {len(audio_files)}\")\n",
        "    return prepare_data(audio_files)"
      ],
      "metadata": {
        "id": "K7td4uO64hgL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normalização"
      ],
      "metadata": {
        "id": "7KDp9tTx4kVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalization(X_train,X_test):\n",
        "    global scaler\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "I6ztQ-3U4l5Q"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparando os dados"
      ],
      "metadata": {
        "id": "Te6XvVD7kUG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_directory = 'AI_Project_Semester2/data/train_audio/AudiosDeTreino'\n",
        "test_data_directory = 'AI_Project_Semester2/data/test_audio/_audios_teste'\n",
        "X_train, y_train = load_data_from_directory(train_data_directory)\n",
        "X_test, y_test = load_data_from_directory(test_data_directory)\n",
        "normalization(X_train, X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTV6x4B4kWPS",
        "outputId": "277759be-00f2-41c7-c195-50d477e64e6b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of audio files: 73\n",
            "Shape of X: (73, 164), Shape of y: (73,)\n",
            "Number of audio files: 25\n",
            "Shape of X: (25, 164), Shape of y: (25,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aplicando Logistic Regression"
      ],
      "metadata": {
        "id": "upxm_JIv5IYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logreg_model = LogisticRegression()\n",
        "logreg_model.fit(X_train, y_train)\n",
        "logreg_predictions = logreg_model.predict(X_test)\n",
        "print('Logistic Regression Accuracy: ', accuracy_score(y_test, logreg_predictions))\n",
        "print('Classification Report for logistic Regression Model:')\n",
        "print(classification_report(y_test, logreg_predictions))"
      ],
      "metadata": {
        "id": "lvhbKx675KpX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74660a88-0710-4417-bb06-94a3ea06dc4a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy:  0.4\n",
            "Classification Report for logistic Regression Model:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Acoba       1.00      1.00      1.00         1\n",
            "        Akio       0.00      0.00      0.00         0\n",
            "      Alexia       0.00      0.00      0.00         0\n",
            "          Ba       0.00      0.00      0.00         1\n",
            "       Cindy       0.00      0.00      0.00         1\n",
            "     Eduardo       0.00      0.00      0.00         2\n",
            "          Ha       1.00      1.00      1.00         2\n",
            "       Harry       1.00      0.50      0.67         2\n",
            "       Nakai       1.00      1.00      1.00         2\n",
            "   Penterist       0.00      0.00      0.00         2\n",
            "     Raphael       1.00      1.00      1.00         2\n",
            "       Ruivo       1.00      1.00      1.00         2\n",
            "        Teko       0.00      0.00      0.00         2\n",
            "         bia       0.00      0.00      0.00         1\n",
            "     eduardo       0.00      0.00      0.00         0\n",
            "    fernanda       0.00      0.00      0.00         1\n",
            "irmamichelli       0.00      0.00      0.00         1\n",
            "    michelli       0.00      0.00      0.00         1\n",
            "      nicole       0.00      0.00      0.00         1\n",
            "      sergio       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.40        25\n",
            "   macro avg       0.30      0.28      0.28        25\n",
            "weighted avg       0.44      0.40      0.41        25\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aplicando SVM"
      ],
      "metadata": {
        "id": "F7dCZkfO52yg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm_clf = SVC()\n",
        "svm_clf.fit(X_train, y_train)\n",
        "svm_predictions = svm_clf.predict(X_test)\n",
        "print('SVM Accuracy: ', accuracy_score(y_test, svm_predictions))\n",
        "print('Classification Report for SVM Model:')\n",
        "print(classification_report(y_test, svm_predictions))"
      ],
      "metadata": {
        "id": "TRxXK5655z5l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf097d72-2cab-431e-d57b-ac5b598111af"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy:  0.44\n",
            "Classification Report for SVM Model:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Acoba       0.00      0.00      0.00         1\n",
            "          Ba       0.50      1.00      0.67         1\n",
            "       Cindy       0.00      0.00      0.00         1\n",
            "     Eduardo       0.00      0.00      0.00         2\n",
            "          Ha       0.00      0.00      0.00         2\n",
            "       Harry       0.33      0.50      0.40         2\n",
            "       Nakai       0.00      0.00      0.00         2\n",
            "   Penterist       0.67      1.00      0.80         2\n",
            "     Raphael       0.40      1.00      0.57         2\n",
            "       Ruivo       1.00      1.00      1.00         2\n",
            "        Teko       0.25      0.50      0.33         2\n",
            "         bia       0.00      0.00      0.00         1\n",
            "    fernanda       0.00      0.00      0.00         1\n",
            "irmamichelli       0.00      0.00      0.00         1\n",
            "    michelli       0.50      1.00      0.67         1\n",
            "      nicole       0.00      0.00      0.00         1\n",
            "      sergio       0.33      1.00      0.50         1\n",
            "\n",
            "    accuracy                           0.44        25\n",
            "   macro avg       0.23      0.41      0.29        25\n",
            "weighted avg       0.27      0.44      0.32        25\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aplicando KNN"
      ],
      "metadata": {
        "id": "1li6XXom5_BG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knn_clf = KNeighborsClassifier()\n",
        "knn_clf.fit(X_train, y_train)\n",
        "knn_predictions = knn_clf.predict(X_test)\n",
        "print('KNN Accuracy: ', accuracy_score(y_test, knn_predictions))\n",
        "print('Classification Report for KNN Model:')\n",
        "print(classification_report(y_test, knn_predictions))"
      ],
      "metadata": {
        "id": "lunkn8-86Bcy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9494e6f1-8d6c-4058-9e86-2997a7852a1c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Accuracy:  0.4\n",
            "Classification Report for KNN Model:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Acoba       0.00      0.00      0.00         1\n",
            "        Akio       0.00      0.00      0.00         0\n",
            "      Alexia       0.00      0.00      0.00         0\n",
            "          Ba       0.50      1.00      0.67         1\n",
            "       Cindy       0.00      0.00      0.00         1\n",
            "     Eduardo       0.40      1.00      0.57         2\n",
            "          Ha       0.00      0.00      0.00         2\n",
            "       Harry       0.33      0.50      0.40         2\n",
            "       Nakai       0.00      0.00      0.00         2\n",
            "   Penterist       1.00      1.00      1.00         2\n",
            "     Raphael       0.00      0.00      0.00         2\n",
            "       Ruivo       1.00      1.00      1.00         2\n",
            "        Teko       0.50      0.50      0.50         2\n",
            "         bia       0.00      0.00      0.00         1\n",
            "    fernanda       0.00      0.00      0.00         1\n",
            "irmamichelli       0.00      0.00      0.00         1\n",
            "    michelli       1.00      1.00      1.00         1\n",
            "      nicole       0.00      0.00      0.00         1\n",
            "      sergio       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.40        25\n",
            "   macro avg       0.25      0.32      0.27        25\n",
            "weighted avg       0.32      0.40      0.34        25\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aplicando Neural Network"
      ],
      "metadata": {
        "id": "PgYqdWhn6CQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nn_clf = MLPClassifier()\n",
        "nn_clf.fit(X_train, y_train)\n",
        "nn_predictions = nn_clf.predict(X_test)\n",
        "print('Neural Network Accuracy: ', accuracy_score(y_test, nn_predictions))\n",
        "print('Classification Report for Neural Network Model:')\n",
        "print(classification_report(y_test, nn_predictions))"
      ],
      "metadata": {
        "id": "tSoaS2hK6G2L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a62c50a-3837-4e1b-9494-d3faf9d26a6e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural Network Accuracy:  0.0\n",
            "Classification Report for Neural Network Model:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Acoba       0.00      0.00      0.00       1.0\n",
            "          Ba       0.00      0.00      0.00       1.0\n",
            "       Cindy       0.00      0.00      0.00       1.0\n",
            "     Eduardo       0.00      0.00      0.00       2.0\n",
            "          Ha       0.00      0.00      0.00       2.0\n",
            "       Harry       0.00      0.00      0.00       2.0\n",
            "       Nakai       0.00      0.00      0.00       2.0\n",
            "   Penterist       0.00      0.00      0.00       2.0\n",
            "     Raphael       0.00      0.00      0.00       2.0\n",
            "       Ruivo       0.00      0.00      0.00       2.0\n",
            "        Teko       0.00      0.00      0.00       2.0\n",
            "         bia       0.00      0.00      0.00       1.0\n",
            "    fernanda       0.00      0.00      0.00       1.0\n",
            "irmamichelli       0.00      0.00      0.00       1.0\n",
            "    michelli       0.00      0.00      0.00       1.0\n",
            "      nicole       0.00      0.00      0.00       1.0\n",
            "      sergio       0.00      0.00      0.00       1.0\n",
            "\n",
            "    accuracy                           0.00      25.0\n",
            "   macro avg       0.00      0.00      0.00      25.0\n",
            "weighted avg       0.00      0.00      0.00      25.0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}